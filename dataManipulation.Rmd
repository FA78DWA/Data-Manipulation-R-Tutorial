---
title: "R Notebook - Data Manipulation"
# output: html_notebook

output:
  md_document:
    variant: markdown_github
    toc: true
    toc_depth: 3
---
# Creating and subsetting dataframes
## Sort & Order
```{r}
set.seed(0)

## create a dataframe with 5 rows, and 3 columns named var1,2,3.
df <- data.frame("var1" = sample(1:5), "var2" = sample(6:10), "var3" = sample(11:15))
df

## randomly re-arrange the rows and set the 1st and the 3rd rows in the var2 column to NA
df <- df[sample(1:5),]; df$var2[c(1,3)] = NA
df

## subsetting the 1st column
df[,1] 

## you can subset the column with ts name
df[,"var1"]

## subsetting the first 2 rows and the 2nd column
df[1:2,"var2"]

## Subset using logical statements. get the columns with rows satisfy var1 <= 3 and var3 > 11
df[(df$var1 <= 3 & df$var3>11),]

## use which to return the indices that satisfy a certain condition
df[which(df$var2 > 8),]

## sort variables in ascending order by default 
sort(df$var1)

## for descending order
sort(df$var1, decreasing = TRUE)

## incase of sorting data with missing variables, we can add them at the end
sort(df$var2, na.last = TRUE)

## re-ordering the rows of the dataframe wrt some variable.
df[order(df$var1),]

## we can sort using 2 variables, so that if there is a tie using the 1st variable, order with the second one
df[order(df$var1,df$var3),]

## ordering with plyr package
library(plyr)
arrange(df, var1) #increasing order

arrange(df, desc(var1)) #decreasing order



```
## Add rows and columns
```{r}
## create the dataframe
df <- data.frame("var1" = sample(1:5), "var2" = sample(6:10), "var3" = sample(11:15))
df

## add var4 contains some random values
df$var4 <- rnorm(5)
df

## another way to do this is using column bind function cbind. It pastes the new column into the right side of the df. If you switch orders the new column will be added into the left side.
df2 <- cbind(df,rnorm(5))
df2

## add rows using row bind function rbind. Order matters just like cbind.
df3 <- rbind(df,rep(100,4))
df3
```

Another way to do this is using column bind function cbind. It pastes the new column into the right side of the df. If you switch orders the new column will be added into the left side.
```{r}
df2 <- cbind(df,rnorm(5))
df2

## add rows using row bind function rbind. Order matters just like cbind.
df3 <- rbind(df,rep(100,4))
df3
```

# Summarizing Data
```{r}
restaurants <- read.csv("Restaurants.csv")

## Show the first 3 rows. Without specifying n, it will give the top 6 rows
head(restaurants, n=3)

## show the last 3 rows. Without specifying n, it will give the last 6 rows
tail(restaurants, n=3)

## make summary. It gives histogram for string columns and quantiles for numeric columns
summary(restaurants)

## more in depth details
str(restaurants)

## Quantiles
quantile(restaurants$councilDistrict, na.rm = T)

## passing probabilities to quantile
quantile(restaurants$councilDistrict, na.rm = T, probs = c(0.5,0.7,0.9))
```
## tables
`table()`  makes a histogram for the input observations. `useNA = "ifany"` will add NA column in the output contains the number of missing values. `table()` can also take 2 variables to construct a 2D histogram.
```{r}
## counting the number of occurence for eah zipcode
table(restaurants$zipCode, useNA = "ifany")

## 2D histogram
table(restaurants$councilDistrict, restaurants$zipCode)

```
## Check for missing values

Use `is.na` to check if the value in na or not. it gives `True` or `False` output with the same size as the input.

Note that in `R`, `True = 1`, and `false = 0`, so we can sum the output of `is.na()` to get the number of `NA` values.
```{r}
## Example
x <- c(1,5,NA, 10, NA)
is.na(x) # we expect the output to be F,F,T,F,T

## number of NAs
sum(is.na(x))
```

If we want to check if there is any `NA` in the input data. we can use `any()` that gives `True` if any of its inputs is `True` and `False` otherwise. 
```{r}
x <- c(1,5,9, 10, NA)
any(is.na(x))
```

To check if every single value satisfies a certain condition, use `all()`
```{r}
y <- c(5,6,7,8,9,10)
## Check if all values in y is greater than 0
all(y>0)
```
## Sum across rows and columns
```{r}
## get the number of NAs in each column
colSums(is.na(restaurants))

## make sure that there is no missing data
all(colSums(is.na(restaurants)) == 0)
```

## Find specific values in your data

Suppose we want to find how many times the zipcode `21212` occurs in our data. Two ways...
```{r}
## method # 1
sum(restaurants$zipCode == "21212")

## method # 2
table(restaurants$zipCode %in% c("21212"))
```

If we are searching for the occurrence of two zipcodes `21212` and `21213`, apply the same methods. The second method is more compact.
```{r}
## method # 1
sum(restaurants$zipCode == "21212" | restaurants$zipCode == "21213")

## method # 2
table(restaurants$zipCode %in% c("21212", "21213"))
```

We can use the output of the previous example to subset our data, by putting the expression in the row subsetting part in `restaurants[rows,columns]`
```{r results = "hide"}
## get the data of all restaurants with zipcode "21212" or "21213". I hide the result because it is big.
restaurants[restaurants$zipCode %in% c("21212", "21213"),]
```

## Cross tabs and Flat tables
```{r}
## load UCB admissions R dataset 
data("UCBAdmissions")

## Read it as a dataframe
df = as.data.frame(UCBAdmissions)

## Summarize data
summary(df)
```

Creating a cross tab that shows the `Freq` relationship between `Gender` and `Admit`. Let's take a look at the syntax below. `Freq ~` means, break `Freq` variable by. So, `Freq ~ Gender+Admit` means break `Freq` by `Gender` and `Admit`. Finally, `data=df` means take these data information from `df` that we already created.
```{r}
xt <- xtabs(Freq ~ Gender+Admit, data = df)
xt

## flat tables gives more compact output
ftable(xt)
```

# Size of the dataset
```{r}
fake = rnorm(1e5)

## output in bytes
object.size(fake)

## change the units of the output to Mb
print(object.size(fake), units="Mb")
```
# Create new variables
## `ifelse`
Given the `restaurants` dataset, we want to add column `falseZip` indicates the wronge zipcodes in this dataset. 
```{r}
## if the zipcode < 0 the output is true (falsezip=true)
restaurants$falsezip = ifelse(restaurants$zipCode < 0, TRUE, FALSE)

## summarize the output using table
table(restaurants$falsezip, restaurants$zipCode < 0)

## we have one false zipcode (-21226)
table(restaurants$falsezip, restaurants$zipCode)
```

## Categorical Variables
We can put our data into groups using `cut()`. The output of `cut` is a **factor variable**.
```{r}
## Break zipcode data into groups wrt quantile output. Each zipcode will have it's group in the zipGroups column
restaurants$zipGroups = cut(restaurants$zipCode, breaks = quantile(restaurants$zipCode))

## summarizing the zipGroups (histogram like table)
table(restaurants$zipGroups)

## summarizing the zipcodes wrt zipGroups
table(restaurants$zipGroups, restaurants$zipCode)

```

**An easier way to do the `cut` task, is to use `Hmisc` package.**
*It will need some other packages `survival`, `ggplot2`, see the error and download what is needed*
```{r}
## Load the library
library(Hmisc)

## cut the zipcodes into 4 groups(g=4) according to quantiles
restaurants$zipGroups = cut2(restaurants$zipCode, g=4)

## summarizing the zipGroups (histogram like table)
table(restaurants$zipGroups)
```
## Factor Variables
It might be intuative not to leave zipcodes as integers, because it will take more space and we will neve add or subtract them. That's why we make zipcode variable a `factor`.
```{r}
restaurants$zipcodeF = factor(restaurants$zipCode)

## looking at the first 10 values. There are 32 different values (levels) of zipcode
restaurants$zipcodeF[1:10]

class(restaurants$zipcodeF)
```

**Another example on factor variables**

In case of character variables, `factor` arranges the levels according to the alphabetical order of the variables. Also, factor variables can be transfered into numerical variables using `as.umeric()`.
```{r}
## create a sample vector of size 10 with yes or no values.
yn <- sample(c("yes","no"), size = 10, replace = T)

## Create a factor variable for the yn variable
## see here factor() will make the first value "alphabetically" as its first level.  
fct <- factor(yn)
fct

## no = 1 because it is the first level, and yes = 2
as.numeric(fct)

## To make yes the first level give factor() the ordered list of levels.
fct <- factor(yn, levels = c("yes", "no"))
fct

## yes = 1 because it is the first level, and no = 2
as.numeric(fct)
```

## Using `mutate` from `plyr` package
We can create new variable and add it to the dataframe one line of code using `mutate`.
```{r}
## load the library
library(plyr)

## creating zipGroups from cutting zipcodes into 4 groups, and add it to the dataframe
restaurants <- mutate(restaurants, zipGroups=cut2(zipCode, g=4))
table(restaurants$zipGroups)
```
# Resahping Data
## `melt` the dataset

Highlighting only certian variables and transform the dataframe into a skinny tall one. The output is `id`, `variable`, and `value` dataframe. *Note that the original dataframe has 32 observations, and the melted one contains 64, that is because for each entry we want to see two variables "mpg" and "hp"*.
 
```{r}
## load library
library(reshape2)

## load mtcars dataset that contains 11 variables(columns), 32 observations(rows)
data("mtcars")
head(mtcars)

## variables names
names(mtcars)

## Melt the dataset. The id is the 3 variables we specified. each entry will have two rows each descriping a variable ("mpg" or "hp")
mtcars$carname <- rownames(mtcars)
carMelt <- melt(mtcars, id = c("carname","gear", "cyl"), measure.vars = c("mpg", "hp"))
head(carMelt)

## re-order the output by name to see that each entry will has two rows for the two variables ("mpg" or "hp")
carMelt[order(carMelt$carname),]

## Another way to re-order is to use arrange(df, by)
arrange(carMelt, carname)
```

## casting dataframes
After melting the dataframe, we can reformat the it into different shapes `dcast`. For example, we want to see how `cyl` variable is related to other variables in the melted dataframe. *remember that we have 2 variables ("mpg" or "hp")*
```{r, message=FALSE, warning=FALSE}
## The output is the summary of the # of "mpg" and "hp" observations for each "cyl" value 
cylData <- dcast(carMelt, cyl ~ variable)
cylData

## For the mean value of "mpg" and "hp" for each "cyl" value 
cylData <- dcast(carMelt, cyl ~ variable, mean)
cylData
```

